{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Start of File\n",
    "# Load Almost All Modules\n",
    "####################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV as gscv\n",
    "from sklearn.metrics import jaccard_score as jcs\n",
    "from sklearn.metrics import f1_score as f1s\n",
    "from sklearn.metrics import log_loss as lls\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ in `loan_test.csv`\n",
    "df = pd.read_csv('loan_train.csv')\n",
    "\n",
    "# PROCESS data into a better format\n",
    "df['due_date'] = pd.to_datetime(df['due_date'])\n",
    "df['effective_date'] = pd.to_datetime(df['effective_date'])\n",
    "df['dayofweek'] = df['effective_date'].dt.dayofweek\n",
    "df['weekend'] = df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\n",
    "df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\n",
    "\n",
    "# FORMAT data\n",
    "Feature = df[['Principal','terms','age','Gender','weekend']]\n",
    "Feature = pd.concat([Feature,pd.get_dummies(df['education'])], axis=1)\n",
    "\n",
    "# REGRESSION TESTING - Train/Test split\n",
    "# ['Principal', 'terms', 'age', 'Gender', 'weekend', 'Bechalor', 'High School or Below', 'Master or Above', 'college']\n",
    "#Feature.drop(['Principal'], axis = 1,inplace=True)\n",
    "#Feature.drop(['terms'], axis = 1,inplace=True)\n",
    "#Feature.drop(['age'], axis = 1,inplace=True)\n",
    "#Feature.drop(['Gender'], axis = 1,inplace=True)\n",
    "#Feature.drop(['weekend'], axis = 1,inplace=True)\n",
    "#Feature.drop(['High School or Below'], axis = 1,inplace=True)\n",
    "#Feature.drop(['Bechalor'], axis = 1,inplace=True)\n",
    "Feature.drop(['Master or Above'], axis = 1,inplace=True)\n",
    "#Feature.drop(['college'], axis = 1,inplace=True)\n",
    "X = Feature\n",
    "y = df['loan_status'].values\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor(KNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 9}\n",
      "0.7461538461538462\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as knnc\n",
    "\n",
    "knn_param = {'n_neighbors':[2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "knn = gscv(knnc(), knn_param, cv=7, scoring='accuracy', refit=True)\n",
    "knn.fit(X_train, y_train)\n",
    "print(knn.best_params_)\n",
    "print(knn.best_score_)\n",
    " \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn.fit(X_test, y_test)\n",
    "# print(knn.best_params_)\n",
    "# print(knn.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 4, 'min_samples_leaf': 1}\n",
      "0.7357142857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "\n",
    "tree_param = { 'criterion':['entropy', 'gini'], 'max_depth':range(3,16,1), 'min_samples_leaf':range(1,8,1)}\n",
    "tree = gscv(dtc(), tree_param, cv=7, scoring='accuracy', refit=True)\n",
    "tree.fit(X_train, y_train)\n",
    "print(tree.best_params_)\n",
    "print(tree.best_score_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.fit(X_test, y_test)\n",
    "# print(tree.best_params_)\n",
    "# print(tree.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.7573260073260073\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_param = {'C':[0.1, 1, 10, 100], 'gamma':[1, 0.1, 0.01, 0.001, 0.0001], 'kernel':['linear', 'rbf', 'sigmoid']}\n",
    "svm = gscv(SVC(), svm_param, cv=7, scoring='accuracy', refit=True)\n",
    "svm.fit(X_train, y_train)\n",
    "print(svm.best_params_)\n",
    "print(svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm.fit(X_test, y_test)\n",
    "# print(svm.best_params_)\n",
    "# print(svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.2636161616161616, 'solver': 'newton-cg'}\n",
      "0.7540293040293039\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lrc\n",
    "\n",
    "lrg_param = {'C':np.linspace(start=0.001, stop=26, num=100), \"solver\":['newton-cg', 'lbfgs', 'liblinear']}\n",
    "lrg = gscv(lrc(), lrg_param, cv=7, scoring='accuracy', refit=True)\n",
    "lrg.fit(X_train, y_train)\n",
    "print(lrg.best_params_)\n",
    "print(lrg.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lrg.fit(X_test, y_test)\n",
    "# print(lrg.best_params_)\n",
    "# print(lrg.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation using Test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test file\n",
    "test_df = pd.read_csv('loan_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['due_date'] = pd.to_datetime(test_df['due_date'])\n",
    "test_df['effective_date'] = pd.to_datetime(test_df['effective_date'])\n",
    "test_df['dayofweek'] = test_df['effective_date'].dt.dayofweek\n",
    "test_df['weekend'] = test_df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\n",
    "test_df['Gender'].replace(to_replace=['male', 'female'], value=[0,1],inplace=True)\n",
    "\n",
    "# set features and paramters similar to testing parameters.\n",
    "Feature1 = test_df[['Principal', 'terms', 'age', 'Gender', 'weekend']]\n",
    "Feature1 = pd.concat([Feature1, pd.get_dummies(test_df['education'])], axis=1)\n",
    "\n",
    "# this feature dropped from testing.\n",
    "Feature1.drop(['Master or Above'], axis = 1, inplace=True)\n",
    "X1 = Feature1\n",
    "y1 = test_df['loan_status'].values\n",
    "X1 = preprocessing.StandardScaler().fit(X1).transform(X1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Jaccard Score: 0.67\n",
      "KNN F1-score: 0.65\n",
      "DTree Jaccard Score: 0.72\n",
      "DTree F1-score: 0.76\n",
      "SVM Jaccard score: 0.76\n",
      "SVM F1-score: 0.76\n",
      "LOG Jaccard score: 0.7451\n",
      "LOG F1-score: 0.7144\n",
      "LOG: 0.47\n"
     ]
    }
   ],
   "source": [
    "# KNN \n",
    "yhatKNN = knn.predict(X1)\n",
    "KNNJaccard = jcs(y1, yhatKNN, pos_label='PAIDOFF')\n",
    "KNNF1 = f1s(y1, yhatKNN, average='weighted')\n",
    "print(\"KNN Jaccard Score: %.2f\" % KNNJaccard)\n",
    "print(\"KNN F1-score: %.2f\" % KNNF1 )\n",
    "\n",
    "# Decision Tree\n",
    "yhatDEC = tree.predict(X1)\n",
    "DTJaccard = jcs(y1, yhatDEC, pos_label='PAIDOFF')\n",
    "DTF1 = f1s(y1, yhatDEC, average='weighted')\n",
    "print(\"DTree Jaccard Score: %.2f\" % DTJaccard)\n",
    "print(\"DTree F1-score: %.2f\" % DTF1 )\n",
    "\n",
    "\n",
    "# Support Vector Machine\n",
    "yhatSVM = svm.predict(X1)\n",
    "SVMJaccard = jcs(y1, yhatSVM, pos_label='PAIDOFF')\n",
    "SVMF1 = f1s(y1, yhatSVM, average='weighted')\n",
    "print(\"SVM Jaccard score: %.2f\" % SVMJaccard)\n",
    "print(\"SVM F1-score: %.2f\" % SVMF1)\n",
    "\n",
    "# Logistic Regression\n",
    "yhatLOG = lrg.predict(X1)\n",
    "yhatLOGproba = lrg.predict_proba(X1)\n",
    "LogRJaccard = jcs(y1, yhatLOG, pos_label='PAIDOFF')\n",
    "LogRF1 = f1s(y1, yhatLOG, average='weighted')\n",
    "Logloss = lls(y1, yhatLOGproba)\n",
    "print(\"LOG Jaccard score: %.4f\" % LogRJaccard)\n",
    "print(\"LOG F1-score: %.4f\" % LogRF1)\n",
    "print(\"LOG: %.2f\" % Logloss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "\n",
    "#### Final result, with a train test split of 20% test, and 'masters and above' droped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Algorithm          | Jaccard | F1-score | LogLoss |\n",
    "| ------------------ | ------- | -------- | ------- |\n",
    "| KNN                | 0.67    | 0.65     | NA      |\n",
    "| Decision Tree      | 0.72    | 0.76     | NA      |\n",
    "| SVM                | 0.76    | 0.76     | NA      |\n",
    "| LogisticRegression | 0.75    | 0.71     | 0.47    |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "908fd4638a4edf205b50378e997b732a6576d3c09000e37ca100245d2ae3a9a5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
